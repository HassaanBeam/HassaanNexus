---
name: Red Team Analysis
slug: red-team-analysis
category: validation
description: Adversarial perspective to find weaknesses
when_to_use:
  - Security analysis
  - Strategy testing
  - Decision validation
  - Launch preparation
best_for: Finding weaknesses before they're exploited
---

# Red Team Analysis

**Purpose**: Adversarial perspective to find weaknesses

## The Concept

Create a team (or mindset) specifically tasked with attacking your plan, finding every flaw, and exposing weaknesses—before real adversaries do.

## Questions to Ask

- If you were trying to defeat this plan, how would you do it?
- What are the weakest points?
- What are we missing?
- What would a hostile competitor do?
- What would a skeptical investor ask?
- Where are the single points of failure?

## Process

1. Assemble a "red team" (separate from plan creators)
2. Give them full permission to be critical
3. Brief them on the plan/system
4. Task them with finding every flaw
5. Let them attack without restrictions
6. Document all vulnerabilities found
7. Address critical weaknesses
8. Repeat if needed

## Red Team Rules

- No sacred cows—everything can be criticized
- Reward finding problems, not hiding them
- Red team acts in good faith (strongest attack)
- Findings are confidential until addressed
- Focus on systemic issues, not personalities

## Applications

| Domain | Red Team Focus |
|--------|----------------|
| Security | Find vulnerabilities before hackers |
| Strategy | Find flaws before market punishes |
| Product | Find issues before customers complain |
| Process | Find failures before they happen |

## Output

Vulnerability assessment with mitigation recommendations
